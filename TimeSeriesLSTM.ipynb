{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danplotkin/LSTM_Time_Series/blob/main/TimeSeriesLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "Dq170vW5qaLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import copy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "metadata": {
        "id": "-AEb8la2qrkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4f7044-1fee-4a25-e5ac-abbf6403f3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "oeoLbbkBTb49",
        "outputId": "a3fbbdab-0854-405d-8ba2-d23ea9ca0358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fad9d6e3830>"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "HOhVc0tzozDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ticker symbol\n",
        "ticker = \"MSFT\"\n",
        "\n",
        "# Set the start and end dates for the data\n",
        "start_date = \"2000-01-01\"\n",
        "end_date = \"2023-04-30\"\n",
        "\n",
        "# Download the data from Yahoo Finance\n",
        "data = yf.download(ticker, start=start_date, end=end_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4N_JQSjrFYH",
        "outputId": "207666bb-a779-4f41-b9f8-765e02299320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "ZdZp4lvXr0Fd",
        "outputId": "b172ade7-7875-492d-a6de-5aac67f965b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Open     High       Low     Close  Adj Close    Volume\n",
              "Date                                                                  \n",
              "2000-01-03  58.68750  59.3125  56.00000  58.28125  36.282242  53228400\n",
              "2000-01-04  56.78125  58.5625  56.12500  56.31250  35.056629  54119000\n",
              "2000-01-05  55.56250  58.1875  54.68750  56.90625  35.426250  64059600\n",
              "2000-01-06  56.09375  56.9375  54.18750  55.00000  34.239552  54976600\n",
              "2000-01-07  54.31250  56.1250  53.65625  55.71875  34.686993  62013600"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7cca211-fb9e-4320-a56a-af52924acf86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>58.68750</td>\n",
              "      <td>59.3125</td>\n",
              "      <td>56.00000</td>\n",
              "      <td>58.28125</td>\n",
              "      <td>36.282242</td>\n",
              "      <td>53228400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>56.78125</td>\n",
              "      <td>58.5625</td>\n",
              "      <td>56.12500</td>\n",
              "      <td>56.31250</td>\n",
              "      <td>35.056629</td>\n",
              "      <td>54119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>55.56250</td>\n",
              "      <td>58.1875</td>\n",
              "      <td>54.68750</td>\n",
              "      <td>56.90625</td>\n",
              "      <td>35.426250</td>\n",
              "      <td>64059600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>56.09375</td>\n",
              "      <td>56.9375</td>\n",
              "      <td>54.18750</td>\n",
              "      <td>55.00000</td>\n",
              "      <td>34.239552</td>\n",
              "      <td>54976600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>54.31250</td>\n",
              "      <td>56.1250</td>\n",
              "      <td>53.65625</td>\n",
              "      <td>55.71875</td>\n",
              "      <td>34.686993</td>\n",
              "      <td>62013600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7cca211-fb9e-4320-a56a-af52924acf86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7cca211-fb9e-4320-a56a-af52924acf86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7cca211-fb9e-4320-a56a-af52924acf86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.drop(labels=['Open', 'High', 'Low', 'Close', 'Volume'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "jmMJZXfWsJYl",
        "outputId": "3e57ebcc-5994-45e2-844d-15f8b55b54fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Adj Close\n",
              "Date                 \n",
              "2000-01-03  36.282242\n",
              "2000-01-04  35.056629\n",
              "2000-01-05  35.426250\n",
              "2000-01-06  34.239552\n",
              "2000-01-07  34.686993"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60942ad2-631c-4a0f-8f7b-9925eec9ba6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>36.282242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>35.056629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>35.426250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>34.239552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>34.686993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60942ad2-631c-4a0f-8f7b-9925eec9ba6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60942ad2-631c-4a0f-8f7b-9925eec9ba6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60942ad2-631c-4a0f-8f7b-9925eec9ba6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Adj Closing Price Over Time"
      ],
      "metadata": {
        "id": "jSYADxXUxwXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df.index, df['Adj Close'])\n",
        "plt.title('Adjusted Closing Price Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Adj Close')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "iB_wUpaTGv1C",
        "outputId": "88d0b035-06bc-4650-ea5b-ab8555bdc2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "xnh6YLaBCyNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_df(df, window_size, future_steps):\n",
        "  df = df.copy()\n",
        "\n",
        "  for i in range(1, window_size + 1):\n",
        "    df[f'Adj Close(t-{i})'] = df['Adj Close'].shift(i)\n",
        "\n",
        "  for i in range(1, future_steps):\n",
        "    df[f'Adj Close(t+{i})'] = df['Adj Close'].shift(-i)\n",
        "\n",
        "  return df.dropna()"
      ],
      "metadata": {
        "id": "yynDLt5e3QtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 5\n",
        "future_steps = 5\n",
        "dataset = prepare_df(df, window_size=window_size, future_steps=future_steps)\n",
        "X = dataset.iloc[:, 1:6].iloc[:, ::-1]\n",
        "y = dataset.iloc[:, 6:]\n",
        "dataset = pd.concat([X, dataset.iloc[:, 0], y], axis=1)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-njHpePxOQLM",
        "outputId": "39513a47-280b-4481-bd35-555a5c2c3730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Adj Close(t-5)  Adj Close(t-4)  Adj Close(t-3)  Adj Close(t-2)  \\\n",
              "Date                                                                         \n",
              "2000-01-10       36.282242       35.056629       35.426250       34.239552   \n",
              "2000-01-11       35.056629       35.426250       34.239552       34.686993   \n",
              "2000-01-12       35.426250       34.239552       34.686993       34.939915   \n",
              "2000-01-13       34.239552       34.686993       34.939915       34.045017   \n",
              "2000-01-14       34.686993       34.939915       34.045017       32.936104   \n",
              "\n",
              "            Adj Close(t-1)  Adj Close  Adj Close(t+1)  Adj Close(t+2)  \\\n",
              "Date                                                                    \n",
              "2000-01-10       34.686993  34.939915       34.045017       32.936104   \n",
              "2000-01-11       34.939915  34.045017       32.936104       33.558655   \n",
              "2000-01-12       34.045017  32.936104       33.558655       34.939915   \n",
              "2000-01-13       32.936104  33.558655       34.939915       35.893166   \n",
              "2000-01-14       33.558655  34.939915       35.893166       33.305740   \n",
              "\n",
              "            Adj Close(t+3)  Adj Close(t+4)  \n",
              "Date                                        \n",
              "2000-01-10       33.558655       34.939915  \n",
              "2000-01-11       34.939915       35.893166  \n",
              "2000-01-12       35.893166       33.305740  \n",
              "2000-01-13       33.305740       32.994476  \n",
              "2000-01-14       32.994476       32.294125  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3ced2a6-5945-4704-a3de-85a0caf1be80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adj Close(t-5)</th>\n",
              "      <th>Adj Close(t-4)</th>\n",
              "      <th>Adj Close(t-3)</th>\n",
              "      <th>Adj Close(t-2)</th>\n",
              "      <th>Adj Close(t-1)</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Adj Close(t+1)</th>\n",
              "      <th>Adj Close(t+2)</th>\n",
              "      <th>Adj Close(t+3)</th>\n",
              "      <th>Adj Close(t+4)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-10</th>\n",
              "      <td>36.282242</td>\n",
              "      <td>35.056629</td>\n",
              "      <td>35.426250</td>\n",
              "      <td>34.239552</td>\n",
              "      <td>34.686993</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>34.045017</td>\n",
              "      <td>32.936104</td>\n",
              "      <td>33.558655</td>\n",
              "      <td>34.939915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-11</th>\n",
              "      <td>35.056629</td>\n",
              "      <td>35.426250</td>\n",
              "      <td>34.239552</td>\n",
              "      <td>34.686993</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>34.045017</td>\n",
              "      <td>32.936104</td>\n",
              "      <td>33.558655</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>35.893166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-12</th>\n",
              "      <td>35.426250</td>\n",
              "      <td>34.239552</td>\n",
              "      <td>34.686993</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>34.045017</td>\n",
              "      <td>32.936104</td>\n",
              "      <td>33.558655</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>35.893166</td>\n",
              "      <td>33.305740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-13</th>\n",
              "      <td>34.239552</td>\n",
              "      <td>34.686993</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>34.045017</td>\n",
              "      <td>32.936104</td>\n",
              "      <td>33.558655</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>35.893166</td>\n",
              "      <td>33.305740</td>\n",
              "      <td>32.994476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-14</th>\n",
              "      <td>34.686993</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>34.045017</td>\n",
              "      <td>32.936104</td>\n",
              "      <td>33.558655</td>\n",
              "      <td>34.939915</td>\n",
              "      <td>35.893166</td>\n",
              "      <td>33.305740</td>\n",
              "      <td>32.994476</td>\n",
              "      <td>32.294125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3ced2a6-5945-4704-a3de-85a0caf1be80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3ced2a6-5945-4704-a3de-85a0caf1be80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3ced2a6-5945-4704-a3de-85a0caf1be80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(dataset, test_size=0.1)"
      ],
      "metadata": {
        "id": "MmJJ_VRrfbBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler().fit(train)"
      ],
      "metadata": {
        "id": "odDcL69ewyZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MicrosoftDataset(Dataset):\n",
        "  def __init__(self, dataset, scaler):\n",
        "    dataset = scaler.transform(dataset)\n",
        "    X, y = dataset[:, :future_steps], dataset[:, future_steps:]\n",
        "    self.X = torch.tensor(np.expand_dims(X, axis=-1)).float()\n",
        "    self.y = torch.tensor(y).float()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "e52dkUBihJWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load in datasets\n",
        "train_ds = MicrosoftDataset(train, scaler)\n",
        "val_ds = MicrosoftDataset(val, scaler)\n",
        "\n",
        "# batch into dataloaders\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "Pa1bnofO1Whu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train Loader Size: {len(train_loader)} \\nValid Loader Size: {len(val_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3qEqYE5-COx",
        "outputId": "182675ce-f05d-431c-94b2-2fb1b4205f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader Size: 165 \n",
            "Valid Loader Size: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_in, ex_out = next(iter(train_loader))\n",
        "print(ex_in.shape, ex_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSCeSEzY2IWR",
        "outputId": "bc0e2c06-ecfc-4486-d71f-49a4f846c953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 5, 1]) torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "_5quMZmKDd7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = 1\n",
        "HIDDEN_SIZE = 64\n",
        "OUTPUT_SIZE = 5\n",
        "NUM_LAYERS = 2\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "TM2JqCMARYKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers, device):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)\n",
        "    out, _ = self.lstm(x, (h0, c0))\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    return out"
      ],
      "metadata": {
        "id": "PG29j1C0HSPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Early Stopper"
      ],
      "metadata": {
        "id": "R9h7To4dpDUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "  def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
        "    self.patience = patience\n",
        "    self.min_delta = min_delta\n",
        "    self.restore_best_weights = restore_best_weights\n",
        "    self.best_model = None\n",
        "    self.best_loss = None\n",
        "    self.counter = 0\n",
        "    self.status = \"\"\n",
        "    \n",
        "  def __call__(self, model, val_loss):\n",
        "    if self.best_loss == None:\n",
        "      self.best_loss = val_loss\n",
        "      self.best_model = copy.deepcopy(model)\n",
        "    elif self.best_loss - val_loss > self.min_delta:\n",
        "      self.best_loss = val_loss\n",
        "      self.counter = 0\n",
        "      self.best_model.load_state_dict(model.state_dict())\n",
        "    elif self.best_loss - val_loss < self.min_delta:\n",
        "      self.counter += 1\n",
        "      if self.counter >= self.patience:\n",
        "        self.status = f\"Stopped on {self.counter}\"\n",
        "        if self.restore_best_weights:\n",
        "          model.load_state_dict(self.best_model.state_dict())\n",
        "        return True\n",
        "    self.status = f\"{self.counter}/{self.patience}\"\n",
        "    return False"
      ],
      "metadata": {
        "id": "3iTrb8zdTaVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Trainer"
      ],
      "metadata": {
        "id": "uAq4zlzPpFxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "  def __init__(self, \n",
        "               train_loader, \n",
        "               val_loader, \n",
        "               criterion, \n",
        "               optimizer, \n",
        "               model,\n",
        "               device,\n",
        "               max_epochs):\n",
        "    self.train_loader = train_loader \n",
        "    self.val_loader = val_loader\n",
        "    self.criterion = criterion\n",
        "    self.optimizer = optimizer\n",
        "    self.model = model.to(device)\n",
        "    self.device = device\n",
        "    self.early_stopper = EarlyStopping(patience=10)\n",
        "    self.max_epochs = max_epochs\n",
        "    self.history = {}\n",
        "    self.output_dir = '/content/drive/MyDrive/Models/TimeSeriesLSTM_Multistep'\n",
        "    self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "\n",
        "  def _train_epoch(self):\n",
        "    self.model.train()\n",
        "    running_loss = 0.00\n",
        "    for batch_idx, (input, truth) in enumerate(self.train_loader):\n",
        "      input, truth = input.to(self.device), truth.to(self.device)\n",
        "      self.optimizer.zero_grad()\n",
        "      pred = self.model(input)\n",
        "      loss = self.criterion(pred, truth)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      running_loss+=loss.item()\n",
        "    \n",
        "    return running_loss/len(self.train_loader)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _eval_epoch(self):\n",
        "    self.model.eval()\n",
        "    running_loss = 0.00\n",
        "    for batch_idx, (input, truth) in enumerate(self.val_loader):\n",
        "      input, truth = input.to(self.device), truth.to(self.device)\n",
        "      pred = self.model(input)\n",
        "      loss = self.criterion(pred, truth)\n",
        "      running_loss+=loss.item()\n",
        "    return running_loss/len(self.val_loader)\n",
        "\n",
        "  def train(self):\n",
        "    best_val_loss = np.inf\n",
        "    best_epoch = 0\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    for epoch in range(self.max_epochs):\n",
        "      print(f'Epoch {epoch+1}/{self.max_epochs}:')\n",
        "\n",
        "      tloss = self._train_epoch()\n",
        "      train_losses.append(tloss)\n",
        "      print(f'Train loss: {tloss:.4f}')\n",
        "  \n",
        "      vloss = self._eval_epoch()\n",
        "      val_losses.append(vloss)\n",
        "      print(f'Val loss: {vloss:.4f}')\n",
        "      \n",
        "      self.scheduler.step(vloss)\n",
        "\n",
        "      if vloss < best_val_loss:\n",
        "        best_val_loss = vloss\n",
        "        best_epoch = epoch + 1\n",
        "\n",
        "      if self.early_stopper(self.model, vloss):\n",
        "        print(f'best epoch: {best_epoch}')\n",
        "        break\n",
        "\n",
        "      print()\n",
        "\n",
        "    print('Training Finished')\n",
        "    torch.save(self.model, self.output_dir)\n",
        "    \n",
        "    self.history = {'train': train_losses, 'val': val_losses}\n",
        "\n",
        "  def evaluate(self):\n",
        "    vloss = self._eval_epoch()\n",
        "    return np.round(vloss, 4)"
      ],
      "metadata": {
        "id": "7C6pJJt3Smxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "i7bpaqZLpIJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(\n",
        "    INPUT_SIZE,\n",
        "    HIDDEN_SIZE,\n",
        "    OUTPUT_SIZE,\n",
        "    NUM_LAYERS,\n",
        "    DEVICE\n",
        ")\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-6, weight_decay=0.01)"
      ],
      "metadata": {
        "id": "YymqUX0hR9AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(ex_in).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dwY5uVjuxGw",
        "outputId": "c25a0ad9-11b6-4bef-c061-d46fd7fd7733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    model=model,\n",
        "    device=DEVICE,\n",
        "    max_epochs=250\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCsYKSuMEXDF",
        "outputId": "31ffaf9e-159c-4cec-9ad7-05c613bb20bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250:\n",
            "Train loss: 0.0775\n",
            "Val loss: 0.0713\n",
            "\n",
            "Epoch 2/250:\n",
            "Train loss: 0.0768\n",
            "Val loss: 0.0706\n",
            "\n",
            "Epoch 3/250:\n",
            "Train loss: 0.0760\n",
            "Val loss: 0.0699\n",
            "\n",
            "Epoch 4/250:\n",
            "Train loss: 0.0753\n",
            "Val loss: 0.0693\n",
            "\n",
            "Epoch 5/250:\n",
            "Train loss: 0.0746\n",
            "Val loss: 0.0686\n",
            "\n",
            "Epoch 6/250:\n",
            "Train loss: 0.0738\n",
            "Val loss: 0.0679\n",
            "\n",
            "Epoch 7/250:\n",
            "Train loss: 0.0732\n",
            "Val loss: 0.0673\n",
            "\n",
            "Epoch 8/250:\n",
            "Train loss: 0.0727\n",
            "Val loss: 0.0667\n",
            "\n",
            "Epoch 9/250:\n",
            "Train loss: 0.0719\n",
            "Val loss: 0.0660\n",
            "\n",
            "Epoch 10/250:\n",
            "Train loss: 0.0711\n",
            "Val loss: 0.0654\n",
            "\n",
            "Epoch 11/250:\n",
            "Train loss: 0.0705\n",
            "Val loss: 0.0648\n",
            "\n",
            "Epoch 12/250:\n",
            "Train loss: 0.0700\n",
            "Val loss: 0.0642\n",
            "\n",
            "Epoch 13/250:\n",
            "Train loss: 0.0693\n",
            "Val loss: 0.0636\n",
            "\n",
            "Epoch 14/250:\n",
            "Train loss: 0.0686\n",
            "Val loss: 0.0630\n",
            "\n",
            "Epoch 15/250:\n",
            "Train loss: 0.0681\n",
            "Val loss: 0.0625\n",
            "\n",
            "Epoch 16/250:\n",
            "Train loss: 0.0674\n",
            "Val loss: 0.0619\n",
            "\n",
            "Epoch 17/250:\n",
            "Train loss: 0.0668\n",
            "Val loss: 0.0613\n",
            "\n",
            "Epoch 18/250:\n",
            "Train loss: 0.0662\n",
            "Val loss: 0.0608\n",
            "\n",
            "Epoch 19/250:\n",
            "Train loss: 0.0655\n",
            "Val loss: 0.0603\n",
            "\n",
            "Epoch 20/250:\n",
            "Train loss: 0.0650\n",
            "Val loss: 0.0598\n",
            "\n",
            "Epoch 21/250:\n",
            "Train loss: 0.0645\n",
            "Val loss: 0.0593\n",
            "\n",
            "Epoch 22/250:\n",
            "Train loss: 0.0639\n",
            "Val loss: 0.0588\n",
            "\n",
            "Epoch 23/250:\n",
            "Train loss: 0.0634\n",
            "Val loss: 0.0583\n",
            "\n",
            "Epoch 24/250:\n",
            "Train loss: 0.0628\n",
            "Val loss: 0.0579\n",
            "\n",
            "Epoch 25/250:\n",
            "Train loss: 0.0623\n",
            "Val loss: 0.0575\n",
            "\n",
            "Epoch 26/250:\n",
            "Train loss: 0.0619\n",
            "Val loss: 0.0571\n",
            "\n",
            "Epoch 27/250:\n",
            "Train loss: 0.0615\n",
            "Val loss: 0.0567\n",
            "\n",
            "Epoch 28/250:\n",
            "Train loss: 0.0611\n",
            "Val loss: 0.0563\n",
            "\n",
            "Epoch 29/250:\n",
            "Train loss: 0.0606\n",
            "Val loss: 0.0560\n",
            "\n",
            "Epoch 30/250:\n",
            "Train loss: 0.0602\n",
            "Val loss: 0.0556\n",
            "\n",
            "Epoch 31/250:\n",
            "Train loss: 0.0599\n",
            "Val loss: 0.0553\n",
            "\n",
            "Epoch 32/250:\n",
            "Train loss: 0.0595\n",
            "Val loss: 0.0551\n",
            "\n",
            "Epoch 33/250:\n",
            "Train loss: 0.0592\n",
            "Val loss: 0.0548\n",
            "\n",
            "Epoch 34/250:\n",
            "Train loss: 0.0589\n",
            "Val loss: 0.0545\n",
            "\n",
            "Epoch 35/250:\n",
            "Train loss: 0.0586\n",
            "Val loss: 0.0543\n",
            "\n",
            "Epoch 36/250:\n",
            "Train loss: 0.0583\n",
            "Val loss: 0.0541\n",
            "\n",
            "Epoch 37/250:\n",
            "Train loss: 0.0580\n",
            "Val loss: 0.0539\n",
            "\n",
            "Epoch 38/250:\n",
            "Train loss: 0.0578\n",
            "Val loss: 0.0537\n",
            "\n",
            "Epoch 39/250:\n",
            "Train loss: 0.0575\n",
            "Val loss: 0.0535\n",
            "\n",
            "Epoch 40/250:\n",
            "Train loss: 0.0573\n",
            "Val loss: 0.0533\n",
            "\n",
            "Epoch 41/250:\n",
            "Train loss: 0.0571\n",
            "Val loss: 0.0531\n",
            "\n",
            "Epoch 42/250:\n",
            "Train loss: 0.0569\n",
            "Val loss: 0.0529\n",
            "\n",
            "Epoch 43/250:\n",
            "Train loss: 0.0566\n",
            "Val loss: 0.0528\n",
            "\n",
            "Epoch 44/250:\n",
            "Train loss: 0.0564\n",
            "Val loss: 0.0526\n",
            "\n",
            "Epoch 45/250:\n",
            "Train loss: 0.0562\n",
            "Val loss: 0.0524\n",
            "\n",
            "Epoch 46/250:\n",
            "Train loss: 0.0560\n",
            "Val loss: 0.0522\n",
            "\n",
            "Epoch 47/250:\n",
            "Train loss: 0.0558\n",
            "Val loss: 0.0520\n",
            "\n",
            "Epoch 48/250:\n",
            "Train loss: 0.0556\n",
            "Val loss: 0.0518\n",
            "\n",
            "Epoch 49/250:\n",
            "Train loss: 0.0554\n",
            "Val loss: 0.0516\n",
            "\n",
            "Epoch 50/250:\n",
            "Train loss: 0.0551\n",
            "Val loss: 0.0514\n",
            "\n",
            "Epoch 51/250:\n",
            "Train loss: 0.0549\n",
            "Val loss: 0.0512\n",
            "\n",
            "Epoch 52/250:\n",
            "Train loss: 0.0547\n",
            "Val loss: 0.0510\n",
            "\n",
            "Epoch 53/250:\n",
            "Train loss: 0.0544\n",
            "Val loss: 0.0508\n",
            "\n",
            "Epoch 54/250:\n",
            "Train loss: 0.0542\n",
            "Val loss: 0.0506\n",
            "\n",
            "Epoch 55/250:\n",
            "Train loss: 0.0539\n",
            "Val loss: 0.0504\n",
            "\n",
            "Epoch 56/250:\n",
            "Train loss: 0.0536\n",
            "Val loss: 0.0501\n",
            "\n",
            "Epoch 57/250:\n",
            "Train loss: 0.0534\n",
            "Val loss: 0.0499\n",
            "\n",
            "Epoch 58/250:\n",
            "Train loss: 0.0531\n",
            "Val loss: 0.0496\n",
            "\n",
            "Epoch 59/250:\n",
            "Train loss: 0.0529\n",
            "Val loss: 0.0494\n",
            "\n",
            "Epoch 60/250:\n",
            "Train loss: 0.0525\n",
            "Val loss: 0.0491\n",
            "\n",
            "Epoch 61/250:\n",
            "Train loss: 0.0523\n",
            "Val loss: 0.0488\n",
            "\n",
            "Epoch 62/250:\n",
            "Train loss: 0.0519\n",
            "Val loss: 0.0485\n",
            "\n",
            "Epoch 63/250:\n",
            "Train loss: 0.0516\n",
            "Val loss: 0.0482\n",
            "\n",
            "Epoch 64/250:\n",
            "Train loss: 0.0513\n",
            "Val loss: 0.0479\n",
            "\n",
            "Epoch 65/250:\n",
            "Train loss: 0.0510\n",
            "Val loss: 0.0476\n",
            "\n",
            "Epoch 66/250:\n",
            "Train loss: 0.0506\n",
            "Val loss: 0.0473\n",
            "\n",
            "Epoch 67/250:\n",
            "Train loss: 0.0502\n",
            "Val loss: 0.0469\n",
            "\n",
            "Epoch 68/250:\n",
            "Train loss: 0.0499\n",
            "Val loss: 0.0466\n",
            "\n",
            "Epoch 69/250:\n",
            "Train loss: 0.0495\n",
            "Val loss: 0.0462\n",
            "\n",
            "Epoch 70/250:\n",
            "Train loss: 0.0491\n",
            "Val loss: 0.0458\n",
            "\n",
            "Epoch 71/250:\n",
            "Train loss: 0.0486\n",
            "Val loss: 0.0455\n",
            "\n",
            "Epoch 72/250:\n",
            "Train loss: 0.0482\n",
            "Val loss: 0.0451\n",
            "\n",
            "Epoch 73/250:\n",
            "Train loss: 0.0478\n",
            "Val loss: 0.0447\n",
            "\n",
            "Epoch 74/250:\n",
            "Train loss: 0.0473\n",
            "Val loss: 0.0442\n",
            "\n",
            "Epoch 75/250:\n",
            "Train loss: 0.0469\n",
            "Val loss: 0.0438\n",
            "\n",
            "Epoch 76/250:\n",
            "Train loss: 0.0464\n",
            "Val loss: 0.0434\n",
            "\n",
            "Epoch 77/250:\n",
            "Train loss: 0.0459\n",
            "Val loss: 0.0429\n",
            "\n",
            "Epoch 78/250:\n",
            "Train loss: 0.0454\n",
            "Val loss: 0.0424\n",
            "\n",
            "Epoch 79/250:\n",
            "Train loss: 0.0449\n",
            "Val loss: 0.0419\n",
            "\n",
            "Epoch 80/250:\n",
            "Train loss: 0.0443\n",
            "Val loss: 0.0414\n",
            "\n",
            "Epoch 81/250:\n",
            "Train loss: 0.0438\n",
            "Val loss: 0.0409\n",
            "\n",
            "Epoch 82/250:\n",
            "Train loss: 0.0432\n",
            "Val loss: 0.0403\n",
            "\n",
            "Epoch 83/250:\n",
            "Train loss: 0.0426\n",
            "Val loss: 0.0398\n",
            "\n",
            "Epoch 84/250:\n",
            "Train loss: 0.0420\n",
            "Val loss: 0.0392\n",
            "\n",
            "Epoch 85/250:\n",
            "Train loss: 0.0413\n",
            "Val loss: 0.0386\n",
            "\n",
            "Epoch 86/250:\n",
            "Train loss: 0.0407\n",
            "Val loss: 0.0380\n",
            "\n",
            "Epoch 87/250:\n",
            "Train loss: 0.0400\n",
            "Val loss: 0.0373\n",
            "\n",
            "Epoch 88/250:\n",
            "Train loss: 0.0393\n",
            "Val loss: 0.0367\n",
            "\n",
            "Epoch 89/250:\n",
            "Train loss: 0.0386\n",
            "Val loss: 0.0360\n",
            "\n",
            "Epoch 90/250:\n",
            "Train loss: 0.0379\n",
            "Val loss: 0.0353\n",
            "\n",
            "Epoch 91/250:\n",
            "Train loss: 0.0371\n",
            "Val loss: 0.0346\n",
            "\n",
            "Epoch 92/250:\n",
            "Train loss: 0.0363\n",
            "Val loss: 0.0338\n",
            "\n",
            "Epoch 93/250:\n",
            "Train loss: 0.0355\n",
            "Val loss: 0.0331\n",
            "\n",
            "Epoch 94/250:\n",
            "Train loss: 0.0347\n",
            "Val loss: 0.0323\n",
            "\n",
            "Epoch 95/250:\n",
            "Train loss: 0.0338\n",
            "Val loss: 0.0315\n",
            "\n",
            "Epoch 96/250:\n",
            "Train loss: 0.0329\n",
            "Val loss: 0.0307\n",
            "\n",
            "Epoch 97/250:\n",
            "Train loss: 0.0321\n",
            "Val loss: 0.0298\n",
            "\n",
            "Epoch 98/250:\n",
            "Train loss: 0.0312\n",
            "Val loss: 0.0290\n",
            "\n",
            "Epoch 99/250:\n",
            "Train loss: 0.0303\n",
            "Val loss: 0.0281\n",
            "\n",
            "Epoch 100/250:\n",
            "Train loss: 0.0293\n",
            "Val loss: 0.0273\n",
            "\n",
            "Epoch 101/250:\n",
            "Train loss: 0.0284\n",
            "Val loss: 0.0264\n",
            "\n",
            "Epoch 102/250:\n",
            "Train loss: 0.0275\n",
            "Val loss: 0.0254\n",
            "\n",
            "Epoch 103/250:\n",
            "Train loss: 0.0264\n",
            "Val loss: 0.0245\n",
            "\n",
            "Epoch 104/250:\n",
            "Train loss: 0.0255\n",
            "Val loss: 0.0236\n",
            "\n",
            "Epoch 105/250:\n",
            "Train loss: 0.0245\n",
            "Val loss: 0.0226\n",
            "\n",
            "Epoch 106/250:\n",
            "Train loss: 0.0235\n",
            "Val loss: 0.0217\n",
            "\n",
            "Epoch 107/250:\n",
            "Train loss: 0.0224\n",
            "Val loss: 0.0207\n",
            "\n",
            "Epoch 108/250:\n",
            "Train loss: 0.0214\n",
            "Val loss: 0.0198\n",
            "\n",
            "Epoch 109/250:\n",
            "Train loss: 0.0204\n",
            "Val loss: 0.0188\n",
            "\n",
            "Epoch 110/250:\n",
            "Train loss: 0.0193\n",
            "Val loss: 0.0178\n",
            "\n",
            "Epoch 111/250:\n",
            "Train loss: 0.0183\n",
            "Val loss: 0.0168\n",
            "\n",
            "Epoch 112/250:\n",
            "Train loss: 0.0173\n",
            "Val loss: 0.0159\n",
            "\n",
            "Epoch 113/250:\n",
            "Train loss: 0.0163\n",
            "Val loss: 0.0149\n",
            "\n",
            "Epoch 114/250:\n",
            "Train loss: 0.0152\n",
            "Val loss: 0.0140\n",
            "\n",
            "Epoch 115/250:\n",
            "Train loss: 0.0142\n",
            "Val loss: 0.0130\n",
            "\n",
            "Epoch 116/250:\n",
            "Train loss: 0.0132\n",
            "Val loss: 0.0121\n",
            "\n",
            "Epoch 117/250:\n",
            "Train loss: 0.0123\n",
            "Val loss: 0.0112\n",
            "\n",
            "Epoch 118/250:\n",
            "Train loss: 0.0113\n",
            "Val loss: 0.0103\n",
            "\n",
            "Epoch 119/250:\n",
            "Train loss: 0.0104\n",
            "Val loss: 0.0094\n",
            "\n",
            "Epoch 120/250:\n",
            "Train loss: 0.0095\n",
            "Val loss: 0.0085\n",
            "\n",
            "Epoch 121/250:\n",
            "Train loss: 0.0086\n",
            "Val loss: 0.0077\n",
            "\n",
            "Epoch 122/250:\n",
            "Train loss: 0.0078\n",
            "Val loss: 0.0070\n",
            "\n",
            "Epoch 123/250:\n",
            "Train loss: 0.0070\n",
            "Val loss: 0.0062\n",
            "\n",
            "Epoch 124/250:\n",
            "Train loss: 0.0062\n",
            "Val loss: 0.0056\n",
            "\n",
            "Epoch 125/250:\n",
            "Train loss: 0.0056\n",
            "Val loss: 0.0049\n",
            "\n",
            "Epoch 126/250:\n",
            "Train loss: 0.0049\n",
            "Val loss: 0.0043\n",
            "\n",
            "Epoch 127/250:\n",
            "Train loss: 0.0043\n",
            "Val loss: 0.0038\n",
            "\n",
            "Epoch 128/250:\n",
            "Train loss: 0.0038\n",
            "Val loss: 0.0033\n",
            "\n",
            "Epoch 129/250:\n",
            "Train loss: 0.0033\n",
            "Val loss: 0.0029\n",
            "\n",
            "Epoch 130/250:\n",
            "Train loss: 0.0029\n",
            "Val loss: 0.0025\n",
            "\n",
            "Epoch 131/250:\n",
            "Train loss: 0.0025\n",
            "Val loss: 0.0022\n",
            "\n",
            "Epoch 132/250:\n",
            "Train loss: 0.0022\n",
            "Val loss: 0.0019\n",
            "\n",
            "Epoch 133/250:\n",
            "Train loss: 0.0019\n",
            "Val loss: 0.0016\n",
            "\n",
            "Epoch 134/250:\n",
            "Train loss: 0.0017\n",
            "Val loss: 0.0014\n",
            "\n",
            "Epoch 135/250:\n",
            "Train loss: 0.0015\n",
            "Val loss: 0.0013\n",
            "\n",
            "Epoch 136/250:\n",
            "Train loss: 0.0013\n",
            "Val loss: 0.0011\n",
            "\n",
            "Epoch 137/250:\n",
            "Train loss: 0.0012\n",
            "Val loss: 0.0010\n",
            "\n",
            "Epoch 138/250:\n",
            "Train loss: 0.0011\n",
            "Val loss: 0.0009\n",
            "\n",
            "Epoch 139/250:\n",
            "Train loss: 0.0010\n",
            "Val loss: 0.0008\n",
            "\n",
            "Epoch 140/250:\n",
            "Train loss: 0.0009\n",
            "Val loss: 0.0008\n",
            "\n",
            "Epoch 141/250:\n",
            "Train loss: 0.0008\n",
            "Val loss: 0.0007\n",
            "\n",
            "Epoch 142/250:\n",
            "Train loss: 0.0008\n",
            "Val loss: 0.0007\n",
            "\n",
            "Epoch 143/250:\n",
            "Train loss: 0.0008\n",
            "Val loss: 0.0007\n",
            "\n",
            "Epoch 144/250:\n",
            "Train loss: 0.0007\n",
            "Val loss: 0.0006\n",
            "\n",
            "Epoch 145/250:\n",
            "Train loss: 0.0007\n",
            "Val loss: 0.0006\n",
            "\n",
            "Epoch 146/250:\n",
            "Train loss: 0.0007\n",
            "Val loss: 0.0006\n",
            "\n",
            "Epoch 147/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0006\n",
            "\n",
            "Epoch 148/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0006\n",
            "\n",
            "Epoch 149/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 150/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 151/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 152/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 153/250:\n",
            "Train loss: 0.0006\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 154/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 155/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 156/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 157/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0005\n",
            "\n",
            "Epoch 158/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 159/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 160/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 161/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 162/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 163/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 164/250:\n",
            "Train loss: 0.0005\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 165/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 166/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 167/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 168/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 169/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 170/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 171/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 172/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0004\n",
            "\n",
            "Epoch 173/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 174/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 175/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 176/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 177/250:\n",
            "Train loss: 0.0004\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 178/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 179/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 180/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 181/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 182/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 183/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 184/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 185/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 186/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 187/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 188/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 189/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 190/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 191/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0003\n",
            "\n",
            "Epoch 192/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 193/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 194/250:\n",
            "Train loss: 0.0003\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 195/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 196/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 197/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 198/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 199/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 200/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 201/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 202/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 203/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 204/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 205/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 206/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 207/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 208/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 209/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 210/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 211/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 212/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 213/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 214/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 215/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 216/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 217/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 218/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 219/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 220/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 221/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 222/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 223/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 224/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 225/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 226/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 227/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 228/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 229/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 230/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 231/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 232/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 233/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 234/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 235/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 236/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 237/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 238/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 239/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 240/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 241/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 242/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 243/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 244/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 245/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 246/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 247/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 248/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 249/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Epoch 250/250:\n",
            "Train loss: 0.0002\n",
            "Val loss: 0.0002\n",
            "\n",
            "Training Finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwmH42XtnlDo",
        "outputId": "c6cf1067-112e-4f43-c156-660b339206a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = torch.load('/content/drive/MyDrive/Models/TimeSeriesLSTM_Multistep').to(DEVICE)"
      ],
      "metadata": {
        "id": "OKBbqOhRIQnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Model RMSE"
      ],
      "metadata": {
        "id": "fGlIphYYpTrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesForecast:\n",
        "  def __init__(self, lstm_model, device, scaler, val_data):\n",
        "    self.model = lstm_model\n",
        "    self.device = device\n",
        "    self.scaler = scaler\n",
        "    self.val_data = val_data\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _predict(self, idx):\n",
        "    X, y = self.val_data.__getitem__(idx)\n",
        "    X = X.unsqueeze(0).to(self.device)\n",
        "    preds = self.model(X)\n",
        "    return X.flatten(), y, preds.flatten(),\n",
        "\n",
        "  def _get_unormalized(self, idx):\n",
        "    X, truth, preds = self._predict(idx)\n",
        "    truth_row = torch.concat([X, truth])\n",
        "    truth_row = truth_row.detach().numpy().reshape(1, -1)\n",
        "    preds_row = torch.concat([X, preds])\n",
        "    preds_row = preds_row.detach().numpy().reshape(1, -1)\n",
        "    return self.scaler.inverse_transform(truth_row), self.scaler.inverse_transform(preds_row)\n",
        "\n",
        "  def get_predictions(self):\n",
        "    truth, preds = [], []\n",
        "    for i, (input, output) in enumerate(self.val_data):\n",
        "      truth_row, preds_row = self._get_unormalized(i)\n",
        "      truth.extend(truth_row.flatten()[future_steps:])\n",
        "      preds.extend(preds_row.flatten()[future_steps:])\n",
        "\n",
        "    return truth, preds\n",
        "\n",
        "  def rmse(self):\n",
        "    truth, preds = self.get_predictions()\n",
        "    mse = mean_squared_error(truth, preds)\n",
        "    return np.sqrt(mse)    "
      ],
      "metadata": {
        "id": "X6-aN_XOEhqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = TimeSeriesForecast(lstm_model, DEVICE, scaler, val_ds)"
      ],
      "metadata": {
        "id": "ksm8IV1TFr5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Validation Root Mean Squared Error: {ts.rmse():.4f}')"
      ],
      "metadata": {
        "id": "86DZ7Av2DmAG",
        "outputId": "0679d41f-a21e-4565-f1af-3530d0792713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Root Mean Squared Error: 4.1903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that for every prediction step, the model on average is $4.19 off the actual Adj Closing Price."
      ],
      "metadata": {
        "id": "2q3n5XZxU714"
      }
    }
  ]
}